{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05aef99f-b8e0-4d9f-9fdb-fe9f96775c7a",
   "metadata": {},
   "source": [
    "# Correct code: With detailed explaination. Is is to get the trend in each plot. For overall trendall the scale has to be equal.\n",
    "# ylim are not same here, so, it might be tough to compare side by side\n",
    "\n",
    "### there are multiple peak events under a annual line! So, the middle of the landfall will be picked based on the hurricane start and end date.\n",
    "### This middle value will be same for all station to have a fair comparison. As it is a storm surge event all of these values are calculated based on the firast station that is KIPOTOPEKE!!!! So it is important to input KK seperately to find out these ranges!\n",
    "\n",
    "# each station should have the same range date for pre-post-landfall!!\n",
    "\n",
    "Baseline magnitude upper and lower threshold are set to isolate the baseline where the interaction is extremely high, like a hurricane/wind induced peaks. Monsoon depression etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af5efeca-1849-48a2-bba2-33390138c1a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Station 1: KK - Directory: F:\\DataExtractionStations\\Station_2012\\KK.csv\n",
      "Max water level date: 2012-10-29 13:18:00, station: KK\n",
      "                Count_6min      Start_DateTime        End_DateTime\n",
      "Labels                                                            \n",
      "Baseline             79190 2012-01-16 00:00:00 2012-12-31 23:00:00\n",
      "Landfall              1681 2012-10-26 01:18:00 2012-11-02 01:18:00\n",
      "Post-hurricane        1680 2012-11-02 01:24:00 2012-11-09 01:18:00\n",
      "Pre-hurricane         1680 2012-10-19 01:18:00 2012-10-26 01:12:00\n",
      "Station 2: LEW - Directory: F:\\DataExtractionStations\\Station_2012\\LEW.csv\n",
      "Max water level date: 2012-10-30 19:00:00, station: LEW\n",
      "                Count_6min      Start_DateTime        End_DateTime\n",
      "Labels                                                            \n",
      "Baseline             79190 2012-01-16 00:00:00 2012-12-31 23:00:00\n",
      "Landfall              1681 2012-10-26 01:18:00 2012-11-02 01:18:00\n",
      "Post-hurricane        1680 2012-11-02 01:24:00 2012-11-09 01:18:00\n",
      "Pre-hurricane         1680 2012-10-19 01:18:00 2012-10-26 01:12:00\n",
      "Station 3: ANN - Directory: F:\\DataExtractionStations\\Station_2012\\ANN.csv\n",
      "Max water level date: 2012-10-30 10:48:00, station: ANN\n",
      "                Count_6min      Start_DateTime        End_DateTime\n",
      "Labels                                                            \n",
      "Baseline             79190 2012-01-16 00:00:00 2012-12-31 23:00:00\n",
      "Landfall              1681 2012-10-26 01:18:00 2012-11-02 01:18:00\n",
      "Post-hurricane        1680 2012-11-02 01:24:00 2012-11-09 01:18:00\n",
      "Pre-hurricane         1680 2012-10-19 01:18:00 2012-10-26 01:12:00\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "################################ READ ME ######################################################\n",
    "Comment Main:\n",
    "There are intermediate comments all over the code. All the comments are very important to understand the functionality of the code.\n",
    "So, here, your job is to read all the comments first then you are going to run the code.\n",
    "################################ READ ME ######################################################\n",
    "\n",
    "\n",
    "\n",
    "Job: Log into the distribuition of NIs magnitude shift during normal and extreme condition\n",
    "\n",
    "Capacity to handle 1 station\n",
    "Notes:\n",
    "Comment_1:\n",
    "After importing the csv, the column headers are remaned from their specific station-wise code\n",
    "to a more generic version: \"TideOnly\", \"Surge\", \"RiverTide\", \"Wave\", and \"AllForcing\"\n",
    "\n",
    "Comment_2:\n",
    "#S1: T = Tide\n",
    "#S2: T+SS = Tide + Surge # Wind pressure was considered, no wave component\n",
    "#S3: T+RF = Tide + River Flow – No Wind/Pressure was considered here.\n",
    "#S4: T+W = Tide + Wave – No Pressure was considered here in the Atlantic as well as the FM CPB model domain. \n",
    "#S5: Atlantic ocean with all component – P/W, wave, river flow\n",
    "#Everything is considered here. For now, observation readings are taken as s5.\n",
    "#====================================================================================================================================#\n",
    "#NLI_1: S2-S1: (T+SS)-T = Tide-Surge-Interaction (TSI) + Contribution of SS\n",
    "#NLI_2: S3-S1: (T+RF)-T = Tide-River-Interaction (TRI) + Contribution of RF\n",
    "#NLI_3: S4-S1: (T+W)-T= Tide-Wave-Interaction (TWI) + Contribution of Wave\n",
    "#NLI_all: S5-S1: (T+SS+RF+W)-T=Tide-Surge-River-Wave-Interaction\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import time\n",
    "import glob\n",
    "from netCDF4 import Dataset\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.stats import linregress\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "%matplotlib qt\n",
    "### annotation function\n",
    "def annotate_r2(x, y, **kwargs):\n",
    "    # Calculate the linear regression\n",
    "    slope, intercept, r_value, p_value, std_err = linregress(x, y)\n",
    "    # Calculate R-squared\n",
    "    r2 = r_value**2\n",
    "    # Plot the annotation with R-squared value\n",
    "    ax = plt.gca()\n",
    "    ax.text(.05, .8, f'$R^2 = {r2:.2f}$', transform=ax.transAxes, fontsize=12, color='black')\n",
    "\n",
    "\n",
    "\n",
    "station_dict = {\n",
    "    \"SP\": \"Sewells Point, VA\",\n",
    "    \"MP\": \"Money Point, VA\",\n",
    "    \"KK\": \"Kiptopeke, VA\",\n",
    "    \"WAC\": \"Wachapreague, VA\",\n",
    "    \"YOR\": \"Yorktown USCG, VA\",\n",
    "    \"WP\": \"Windmill Point, VA\",\n",
    "    \"OC\": \"Ocean City Inlet, MD\",\n",
    "    \"LEW\": \"Lewisetta, VA\",\n",
    "    \"SI\": \"Solomons Island, MD\",\n",
    "    \"DC\": \"Washington, DC\",\n",
    "    \"BH\": \"Bishops Head, MD\",\n",
    "    \"CC\": \"Chesapeake City, MD\",\n",
    "    \"BAL\": \"Baltimore, MD\",\n",
    "    \"TB\": \"Tolchester Beach, MD\",\n",
    "    \"ANN\": \"Annapolis, MD\",\n",
    "    \"CAM\": \"Cambridge, MD\",\n",
    "    \"DAH\": \"Dahlgren, VA\",\n",
    "    \"CBBT\": \"CBBT, Chesapeake Channel, VA\"\n",
    "}\n",
    "\n",
    "\n",
    "# importing and formating the data to standard format. See comment_1\n",
    "\n",
    "\n",
    "####################### INPUT START #############################\n",
    "# The middle window is taken as 7 days and similarly the pre-post window is taken as 7 days.\n",
    "# This 7 days section are valid for Sandy 2012 and it was based on it, so shorter-faster hurriane this might not have been the case.\n",
    "# So understand this therefore it is extreme important to plot the time-series and judge.\n",
    "# Again the concern is, will this different time windows be valid fo comparative analysis?\n",
    "\n",
    "timedelta_landfall= pd.Timedelta(days=3.5)\n",
    "timedelta_X2= pd.Timedelta(days=7.0)\n",
    "\n",
    "# the code is going to search for the peak water level within this period and then assign the 7 days window for pre-landfall and post-hurricane\n",
    "# here for Irene the landfall is 27th of August 2011\n",
    "# here for Sandy the landfall is 29th of September 2011\n",
    "\n",
    "hurricane_start = pd.to_datetime('2012-10-26')\n",
    "hurricane_end = pd.to_datetime('2012-11-02')\n",
    "\n",
    "fig, axs = plt.subplots(4, 3, figsize=(15, 18))\n",
    "\n",
    "stations = ['KK', 'LEW', 'ANN']\n",
    "input_directory = r'F:\\DataExtractionStations\\Station_2012'\n",
    "\n",
    "ensemble_size = 500\n",
    "\n",
    "baseline_upper_threshold=0.40\n",
    "baseline_lower_threshold=-0.40\n",
    "####################### INPUT END #############################\n",
    "\n",
    "for station_index, station in enumerate(stations):\n",
    "    directory_path = f\"{input_directory}\\\\{station}.csv\"\n",
    "    print(f\"Station {station_index + 1}: {station} - Directory: {directory_path}\")\n",
    "\n",
    "    \n",
    "    data_raw=pd.read_csv(directory_path)\n",
    "\n",
    "# the renaming of the legends will be done after searching the file name for each specfic term denoted below.\n",
    "    rename_mapping = {\n",
    "        'TideOnly': 'Harmonic Tide',\n",
    "        'Surge': 'Surge',\n",
    "        'RiverTide': 'RiverTide',\n",
    "        'Wave': 'Wave',\n",
    "        'AllForcing': 'AllForcing'\n",
    "    }\n",
    "    data_raw.rename(columns=lambda x: next((v for k, v in rename_mapping.items() if k in x), x), inplace=True)\n",
    "    \n",
    "    # See comment 2\n",
    "    data_raw['TSI+SS'] = data_raw['Surge'] - data_raw['Harmonic Tide']\n",
    "    data_raw['TRI+RF'] = data_raw['RiverTide'] - data_raw['Harmonic Tide']\n",
    "    data_raw['TWI+WV'] = data_raw['Wave'] - data_raw['Harmonic Tide']\n",
    "    data_raw['TSRWI'] = data_raw['AllForcing'] - data_raw['Harmonic Tide']\n",
    "    \n",
    "    # isolate the required data for plotting\n",
    "    data_df = data_raw[['DateTime (GMT)', 'AllForcing','Harmonic Tide', 'TSI+SS', 'TRI+RF', 'TWI+WV', 'TSRWI']]\n",
    "    \n",
    "    ####################### INPUT START #############################\n",
    "    data_df = data_df.iloc[10*24*15:,:].reset_index(drop=True) # dropping initial 15 days worth of data for statbility\n",
    "    \n",
    "    ####################### INPUT END #############################\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Comment_3:\n",
    "    segmentation description: \n",
    "    \n",
    "    Hurricane_landfall: \n",
    "    Peak WL level time for station is found out based on the AllForcing simulation waterlevel (standard). \n",
    "    Checks set, if its within the landfall timeboudnary 10/29/2012 - 10/30/2012. \n",
    "    Then 3.5 days prior and post this to this index is taken as peak hurricane landfall timeline.\n",
    "    For example: KK-max water level is at '2012-10-30 10:48:00' value: 0.7862355799560957. The labels for 7 days centering at this peak\n",
    "    is set as hurricane land fall. \n",
    "    \n",
    "    pre-hurricane: 7-day prior \n",
    "    post-hurricane: 7-day post\n",
    "    Baseline: 16-Jan-2020 to 31-Dec-2020; Except: Timelines for landfall, pre-hurricane and post-hurricane\n",
    "    \"\"\"\n",
    "    \n",
    "    #--------------------------Details in comment_3 creating dividing labels within the dataframe ---------------------------\n",
    "    data_df['DateTime (GMT)'] = pd.to_datetime(data_df['DateTime (GMT)'], format='%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    # Maximum WLvalue and corresponding datelue, to find hurricance landfall date\n",
    "    \n",
    "    # finding out the landfall date!\n",
    "    # Maximum WLvalue and corresponding datelue, to find hurricance landfall date\n",
    "    # Filter data to include only rows within the hurricane timeframe\n",
    "\n",
    "    \n",
    "    data_df_hurricane = data_df[(data_df['DateTime (GMT)'] >= hurricane_start) & \n",
    "                                 (data_df['DateTime (GMT)'] <= hurricane_end)]\n",
    "    \n",
    "    # Find the maximum water level within the hurricane period\n",
    "    max_wl = data_df_hurricane['AllForcing'].max()\n",
    "    \n",
    "    # Find the corresponding date for the max water level within the hurricane period\n",
    "    max_wl_date = data_df_hurricane.loc[data_df_hurricane['AllForcing'] == max_wl, 'DateTime (GMT)'].iloc[0]\n",
    "    \n",
    "    print(f\"Max water level date: {max_wl_date}, station: {station}\")\n",
    "\n",
    "\n",
    "############################ Fixing the landfall date center based on the coastal station!#######################\n",
    "    ############################ It will be same for all other station ##########################################\n",
    "    # Check if the date is within the specified range\n",
    "    if not (hurricane_start <= max_wl_date <= hurricane_end):\n",
    "        warning_message = f\"Warning: Maximum 'AllForcing' value occurs on {max_value_date}, which is outside the specified date range.\"\n",
    "        warning_message\n",
    "    \n",
    "    if station == 'KK': \n",
    "    # Define landfall, pre-hurricane, and post-hurricane periods\n",
    "        landfall_start = max_wl_date - timedelta_landfall\n",
    "        landfall_end = max_wl_date + timedelta_landfall\n",
    "    \n",
    "        pre_hurricane_start = landfall_start - timedelta_X2\n",
    "        pre_hurricane_end = landfall_start\n",
    "        \n",
    "        post_hurricane_start = landfall_end\n",
    "        post_hurricane_end = landfall_end + timedelta_X2\n",
    "############################ Fixing the landfall date center based on the coastal station!#######################\n",
    "    \n",
    "    # Add the 'Labels' column with default 'Baseline' value\n",
    "    data_df['Labels'] = 'Baseline'\n",
    "\n",
    "    # Label the rows accoding to to the data range\n",
    "    data_df.loc[(data_df['DateTime (GMT)'] >= landfall_start) & (data_df['DateTime (GMT)'] <= landfall_end), 'Labels'] = 'Landfall'\n",
    "    data_df.loc[(data_df['DateTime (GMT)'] >= pre_hurricane_start) & (data_df['DateTime (GMT)'] < pre_hurricane_end), 'Labels'] = 'Pre-hurricane'\n",
    "    data_df.loc[(data_df['DateTime (GMT)'] > post_hurricane_start) & (data_df['DateTime (GMT)'] <= post_hurricane_end), 'Labels'] = 'Post-hurricane'\n",
    "    \n",
    "    # Combine the counts with the start and end datetimes for each categorical value\n",
    "    label_summary = data_df.groupby('Labels').agg(\n",
    "        Count_6min=('DateTime (GMT)', 'size'),\n",
    "        Start_DateTime=('DateTime (GMT)', 'min'),\n",
    "        End_DateTime=('DateTime (GMT)', 'max')\n",
    "    )\n",
    "    \n",
    "    # Display the combined summary\n",
    "    print(label_summary)\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    The baseline data contains 79,190 data points, which is 50 times more than the data points available for landfall and \n",
    "    pre/post-hurricane conditions. To create a representative and comparable KDE plot, the baseline data needed to be sampled.\n",
    "    \n",
    "    If a single sample was taken, it might miss important underlying trends, such as the highly right-skewed distribution\n",
    "    observed in the TRI+RF data. To better capture these trends, a Monte Carlo sampling approach with 10,000 iteration can be applied.\n",
    "    However, this will casue scaling issue. \n",
    "    \n",
    "    In the first iteration (i == 1), where all the KDE are plotted together,\n",
    "    you're plotting the KDEs for all labels, including 'Baseline' and others like 'Pre-Hurricane', 'Hurricane', and 'Post-Hurricane', \n",
    "    This dataset combines the subsampled 'Baseline' data with all other label data, resulting in each label appear smaller. As all \n",
    "    the area under the curve ultimately sums up to 1.\n",
    "    \n",
    "    This is because the KDEs are normalized within each label, leading to overlapping distributions.\n",
    "    \n",
    "    In the other iterations (i != 1), you’re only plotting the KDE for the 'Baseline' subsample, \n",
    "    without including the other labels. As a result, the KDE plots in these iterations, especially the blue curves\n",
    "    representing 'Baseline', appear larger because only this single category is being plotted. Without the influence of other labels, \n",
    "    the 'Baseline' KDE becomes more prominent and occupies more space in the plot.\n",
    "    The KDE plots in these iterations appear larger, especially the blue curves (representing the 'Baseline'), \n",
    "    because only this single category is being plotted without the normalization effect across multiple labels\n",
    "    \n",
    "    \n",
    "    Therefore, her, I have resorted to a simple random selection of non-extreme datapoints.\n",
    "    I have 1000 ensembles that goes thorugh the 79190 data oiubts abd collects 1680n data points and plots the kde plots everytimes.\n",
    "    \n",
    "    The custom linestyle allows to make the plots for the pre-post-hurricane invisible by setting the linewidth =0\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    ####################### INPUT START#############################\n",
    "    data_labeled_df=data_df.drop(columns=['AllForcing'])\n",
    "    # isolating non-baseline event from the dataset.\n",
    "    # Apply the threshold filter specifically for rows labeled as 'Baseline'\n",
    "    data_labeled_df = data_labeled_df[\n",
    "        ((data_labeled_df['TSRWI'] >= baseline_lower_threshold) & \n",
    "         (data_labeled_df['TSRWI'] <= baseline_upper_threshold)) | \n",
    "        (data_labeled_df['Labels'] != 'Baseline')\n",
    "    ]\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    # Find the minimum count across labels (other than Baseline) to set the sampling count.\n",
    "    min_count = data_labeled_df['Labels'].value_counts().min()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    first_iteration_styles = {\n",
    "        'Pre-hurricane': { 'color': 'darkorange', 'linewidth': 3.25, 'alpha': 1.0},\n",
    "        'Landfall': { 'color': 'red', 'linewidth': 3.25, 'alpha': 1.0},\n",
    "        'Post-hurricane': { 'color': 'green', 'linewidth': 3.25, 'alpha': 1.0},\n",
    "        'Baseline': {'color': 'blue', 'linewidth': 0.25, 'alpha': 0.20}\n",
    "    }\n",
    "    \n",
    "    # different color are set to detect code crush\n",
    "    subsequent_iteration_styles = {\n",
    "        'Pre-hurricane': { 'color': 'orange', 'linewidth': 0, 'alpha': 0.3},\n",
    "        'Landfall': { 'color': 'brown', 'linewidth': 0, 'alpha': 0.4},\n",
    "        'Post-hurricane': { 'color': 'cyan', 'linewidth': 0, 'alpha': 0.5},\n",
    "        'Baseline': {'color': 'blue', 'linewidth': 0.15, 'alpha': 0.05}\n",
    "    }\n",
    "    \n",
    "    \n",
    "    \n",
    "    ####################### INPUT END #############################\n",
    "    \n",
    "    # Initialize a list to keep track of plotted labels\n",
    "    plotted_labels = []\n",
    "    \n",
    "    \n",
    "    for i in range(ensemble_size):\n",
    "        # Subsample Baseline data to smallest label category count, random sampling [MC not used]\n",
    "        baseline_subsample = data_labeled_df[data_labeled_df['Labels'] == 'Baseline'].sample(n=min_count, random_state=None)\n",
    "        # creating unified dataframe form sampled data\n",
    "        data_balanced_df = pd.concat([baseline_subsample, data_labeled_df[data_labeled_df['Labels'] != 'Baseline']]) \n",
    "    \n",
    "        # setting kde plot labels and iterating through subplot position\n",
    "        if i == 0: # iteration 0 used for label and all kde plot accept Baseline\n",
    "            custom_styles = first_iteration_styles\n",
    "        else:\n",
    "            custom_styles = subsequent_iteration_styles\n",
    "    \n",
    "        for r, (ax, variable) in enumerate(zip(axs[:,station_index], ['TSI+SS', 'TRI+RF', 'TWI+WV', 'TSRWI'])):  # This will be the station iteration\n",
    "            for label in data_balanced_df['Labels'].unique():\n",
    "                \n",
    "                if label not in plotted_labels:\n",
    "                    sns.kdeplot(\n",
    "                        data=data_balanced_df[data_balanced_df['Labels'] == label],\n",
    "                        x=variable,\n",
    "                        ax=ax,\n",
    "                        common_norm=True,\n",
    "                        alpha=custom_styles[label]['alpha'],\n",
    "                        color=custom_styles[label]['color'],\n",
    "                        linewidth=custom_styles[label]['linewidth'],\n",
    "                        label=label  # Add the label for the legend\n",
    "                    )\n",
    "                    plotted_labels.append(label)\n",
    "                else:\n",
    "                    sns.kdeplot(\n",
    "                        data=data_balanced_df[data_balanced_df['Labels'] == label],\n",
    "                        x=variable,\n",
    "                        ax=ax,\n",
    "                        common_norm=True,\n",
    "                        alpha=custom_styles[label]['alpha'],\n",
    "                        color=custom_styles[label]['color'],\n",
    "                        linewidth=custom_styles[label]['linewidth']\n",
    "                    )\n",
    "    \n",
    "            if r == 0:\n",
    "                ax.set_title(station_dict[station],fontsize=15)\n",
    "                \n",
    "            ax.set_xlabel(f'{variable} Magnitude (m)')\n",
    "\n",
    "            ax.set_xlabel(f'{variable} Magnitude (m)', fontsize=15)  # X-label in font size 12\n",
    "            ax.set_ylabel('Density', fontsize=16)  # Y-label in font size 12\n",
    "            \n",
    "            # Set tick parameters for both x and y axes with fontsize 12\n",
    "            ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "                \n",
    "    \n",
    "    \n",
    "    \n",
    "handles, labels = axs[0, 0].get_legend_handles_labels()\n",
    "labels[0]='Baseline Ensemble'\n",
    "fig.legend(handles, labels, loc='upper right', bbox_to_anchor=(0.98, 0.735), bbox_transform=plt.gcf().transFigure, ncol=1, frameon=True, fontsize=16)\n",
    "\n",
    "# Adjust layout for clarity\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8400e39-a146-4251-b6e4-7f723919f010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateTime (GMT)</th>\n",
       "      <th>Harmonic Tide</th>\n",
       "      <th>TSI+SS</th>\n",
       "      <th>TRI+RF</th>\n",
       "      <th>TWI+WV</th>\n",
       "      <th>TSRWI</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71793</th>\n",
       "      <td>2011-11-11 03:18:00</td>\n",
       "      <td>-0.005926</td>\n",
       "      <td>-0.240650</td>\n",
       "      <td>0.012269</td>\n",
       "      <td>-0.261779</td>\n",
       "      <td>-0.242609</td>\n",
       "      <td>Baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12668</th>\n",
       "      <td>2011-03-09 18:48:00</td>\n",
       "      <td>-0.049959</td>\n",
       "      <td>-0.014087</td>\n",
       "      <td>0.061635</td>\n",
       "      <td>0.091257</td>\n",
       "      <td>0.033794</td>\n",
       "      <td>Baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66305</th>\n",
       "      <td>2011-10-19 06:30:00</td>\n",
       "      <td>0.066635</td>\n",
       "      <td>-0.072909</td>\n",
       "      <td>0.019043</td>\n",
       "      <td>-0.073640</td>\n",
       "      <td>-0.057179</td>\n",
       "      <td>Baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68343</th>\n",
       "      <td>2011-10-27 18:18:00</td>\n",
       "      <td>0.011930</td>\n",
       "      <td>-0.205325</td>\n",
       "      <td>0.012660</td>\n",
       "      <td>-0.073957</td>\n",
       "      <td>-0.199424</td>\n",
       "      <td>Baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33199</th>\n",
       "      <td>2011-06-03 07:54:00</td>\n",
       "      <td>0.078932</td>\n",
       "      <td>-0.191525</td>\n",
       "      <td>0.012889</td>\n",
       "      <td>-0.191645</td>\n",
       "      <td>-0.183249</td>\n",
       "      <td>Baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56270</th>\n",
       "      <td>2011-09-07 11:00:00</td>\n",
       "      <td>-0.008436</td>\n",
       "      <td>0.112396</td>\n",
       "      <td>0.065675</td>\n",
       "      <td>0.080040</td>\n",
       "      <td>0.186379</td>\n",
       "      <td>Post-hurricane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56271</th>\n",
       "      <td>2011-09-07 11:06:00</td>\n",
       "      <td>-0.010334</td>\n",
       "      <td>0.114610</td>\n",
       "      <td>0.065134</td>\n",
       "      <td>0.081250</td>\n",
       "      <td>0.188405</td>\n",
       "      <td>Post-hurricane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56272</th>\n",
       "      <td>2011-09-07 11:12:00</td>\n",
       "      <td>-0.011856</td>\n",
       "      <td>0.116761</td>\n",
       "      <td>0.064573</td>\n",
       "      <td>0.082402</td>\n",
       "      <td>0.190239</td>\n",
       "      <td>Post-hurricane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56273</th>\n",
       "      <td>2011-09-07 11:18:00</td>\n",
       "      <td>-0.012988</td>\n",
       "      <td>0.118766</td>\n",
       "      <td>0.063997</td>\n",
       "      <td>0.083429</td>\n",
       "      <td>0.191745</td>\n",
       "      <td>Post-hurricane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56274</th>\n",
       "      <td>2011-09-07 11:24:00</td>\n",
       "      <td>-0.013695</td>\n",
       "      <td>0.120537</td>\n",
       "      <td>0.063383</td>\n",
       "      <td>0.084287</td>\n",
       "      <td>0.192893</td>\n",
       "      <td>Post-hurricane</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6721 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           DateTime (GMT)  Harmonic Tide    TSI+SS    TRI+RF    TWI+WV  \\\n",
       "71793 2011-11-11 03:18:00      -0.005926 -0.240650  0.012269 -0.261779   \n",
       "12668 2011-03-09 18:48:00      -0.049959 -0.014087  0.061635  0.091257   \n",
       "66305 2011-10-19 06:30:00       0.066635 -0.072909  0.019043 -0.073640   \n",
       "68343 2011-10-27 18:18:00       0.011930 -0.205325  0.012660 -0.073957   \n",
       "33199 2011-06-03 07:54:00       0.078932 -0.191525  0.012889 -0.191645   \n",
       "...                   ...            ...       ...       ...       ...   \n",
       "56270 2011-09-07 11:00:00      -0.008436  0.112396  0.065675  0.080040   \n",
       "56271 2011-09-07 11:06:00      -0.010334  0.114610  0.065134  0.081250   \n",
       "56272 2011-09-07 11:12:00      -0.011856  0.116761  0.064573  0.082402   \n",
       "56273 2011-09-07 11:18:00      -0.012988  0.118766  0.063997  0.083429   \n",
       "56274 2011-09-07 11:24:00      -0.013695  0.120537  0.063383  0.084287   \n",
       "\n",
       "          TSRWI          Labels  \n",
       "71793 -0.242609        Baseline  \n",
       "12668  0.033794        Baseline  \n",
       "66305 -0.057179        Baseline  \n",
       "68343 -0.199424        Baseline  \n",
       "33199 -0.183249        Baseline  \n",
       "...         ...             ...  \n",
       "56270  0.186379  Post-hurricane  \n",
       "56271  0.188405  Post-hurricane  \n",
       "56272  0.190239  Post-hurricane  \n",
       "56273  0.191745  Post-hurricane  \n",
       "56274  0.192893  Post-hurricane  \n",
       "\n",
       "[6721 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_balanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15a4c84c-e4d9-42d0-90cb-b636a8f5d1d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateTime (GMT)</th>\n",
       "      <th>Harmonic Tide</th>\n",
       "      <th>TSI+SS</th>\n",
       "      <th>TRI+RF</th>\n",
       "      <th>TWI+WV</th>\n",
       "      <th>TSRWI</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-16 00:00:00</td>\n",
       "      <td>-0.000303</td>\n",
       "      <td>0.026484</td>\n",
       "      <td>0.002133</td>\n",
       "      <td>0.139975</td>\n",
       "      <td>0.036253</td>\n",
       "      <td>Baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-16 00:06:00</td>\n",
       "      <td>-0.000783</td>\n",
       "      <td>0.028737</td>\n",
       "      <td>0.002164</td>\n",
       "      <td>0.141346</td>\n",
       "      <td>0.038428</td>\n",
       "      <td>Baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-16 00:12:00</td>\n",
       "      <td>-0.000978</td>\n",
       "      <td>0.030892</td>\n",
       "      <td>0.002188</td>\n",
       "      <td>0.142825</td>\n",
       "      <td>0.040530</td>\n",
       "      <td>Baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-16 00:18:00</td>\n",
       "      <td>-0.000897</td>\n",
       "      <td>0.033351</td>\n",
       "      <td>0.002205</td>\n",
       "      <td>0.144742</td>\n",
       "      <td>0.042967</td>\n",
       "      <td>Baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-16 00:24:00</td>\n",
       "      <td>-0.000533</td>\n",
       "      <td>0.035922</td>\n",
       "      <td>0.002217</td>\n",
       "      <td>0.146837</td>\n",
       "      <td>0.045558</td>\n",
       "      <td>Baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83986</th>\n",
       "      <td>2011-12-31 22:36:00</td>\n",
       "      <td>0.001765</td>\n",
       "      <td>-0.329691</td>\n",
       "      <td>0.017297</td>\n",
       "      <td>-0.226313</td>\n",
       "      <td>-0.302975</td>\n",
       "      <td>Baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83987</th>\n",
       "      <td>2011-12-31 22:42:00</td>\n",
       "      <td>0.007922</td>\n",
       "      <td>-0.331081</td>\n",
       "      <td>0.016991</td>\n",
       "      <td>-0.229799</td>\n",
       "      <td>-0.303931</td>\n",
       "      <td>Baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83988</th>\n",
       "      <td>2011-12-31 22:48:00</td>\n",
       "      <td>0.014227</td>\n",
       "      <td>-0.332509</td>\n",
       "      <td>0.016708</td>\n",
       "      <td>-0.233279</td>\n",
       "      <td>-0.305004</td>\n",
       "      <td>Baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83989</th>\n",
       "      <td>2011-12-31 22:54:00</td>\n",
       "      <td>0.020680</td>\n",
       "      <td>-0.333922</td>\n",
       "      <td>0.016450</td>\n",
       "      <td>-0.236618</td>\n",
       "      <td>-0.306108</td>\n",
       "      <td>Baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83990</th>\n",
       "      <td>2011-12-31 23:00:00</td>\n",
       "      <td>0.027259</td>\n",
       "      <td>-0.335350</td>\n",
       "      <td>0.016216</td>\n",
       "      <td>-0.239823</td>\n",
       "      <td>-0.307279</td>\n",
       "      <td>Baseline</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83991 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           DateTime (GMT)  Harmonic Tide    TSI+SS    TRI+RF    TWI+WV  \\\n",
       "0     2011-01-16 00:00:00      -0.000303  0.026484  0.002133  0.139975   \n",
       "1     2011-01-16 00:06:00      -0.000783  0.028737  0.002164  0.141346   \n",
       "2     2011-01-16 00:12:00      -0.000978  0.030892  0.002188  0.142825   \n",
       "3     2011-01-16 00:18:00      -0.000897  0.033351  0.002205  0.144742   \n",
       "4     2011-01-16 00:24:00      -0.000533  0.035922  0.002217  0.146837   \n",
       "...                   ...            ...       ...       ...       ...   \n",
       "83986 2011-12-31 22:36:00       0.001765 -0.329691  0.017297 -0.226313   \n",
       "83987 2011-12-31 22:42:00       0.007922 -0.331081  0.016991 -0.229799   \n",
       "83988 2011-12-31 22:48:00       0.014227 -0.332509  0.016708 -0.233279   \n",
       "83989 2011-12-31 22:54:00       0.020680 -0.333922  0.016450 -0.236618   \n",
       "83990 2011-12-31 23:00:00       0.027259 -0.335350  0.016216 -0.239823   \n",
       "\n",
       "          TSRWI    Labels  \n",
       "0      0.036253  Baseline  \n",
       "1      0.038428  Baseline  \n",
       "2      0.040530  Baseline  \n",
       "3      0.042967  Baseline  \n",
       "4      0.045558  Baseline  \n",
       "...         ...       ...  \n",
       "83986 -0.302975  Baseline  \n",
       "83987 -0.303931  Baseline  \n",
       "83988 -0.305004  Baseline  \n",
       "83989 -0.306108  Baseline  \n",
       "83990 -0.307279  Baseline  \n",
       "\n",
       "[83991 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_labeled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badbb53a-ef67-46f4-8b0c-31c6cd4a752f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab34f967-a1d0-4af0-87a2-e7f4f3526835",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e15ad8-21ca-456e-b697-155a907b7285",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b870861-4712-4b31-9e74-4cf209358aa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0aacab-ec5f-40fa-aee9-c7d4fe06a31b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
